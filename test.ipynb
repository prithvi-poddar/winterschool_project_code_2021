{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(x, filters):\n",
    "    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "\n",
    "def dense_bn(x, filters):\n",
    "    x = layers.Dense(filters)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "\n",
    "def tnet(inputs, num_features):\n",
    "    \"\"\"\n",
    "    This is the core t-net of the pointnet paper\n",
    "    :param inputs: the input tensor\n",
    "    :type inputs: tensor\n",
    "    :param num_features: number of features in the tensor (3 for point cloud, N if N features)\n",
    "    :type num_features: int\n",
    "    :return: output tensor\n",
    "    :rtype: tensor\n",
    "    \"\"\"\n",
    "\n",
    "    # Initalise bias as the indentity matrix\n",
    "    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n",
    "\n",
    "    # TODO: Build the tnet with the following layers\n",
    "    # Some convolutional layers (1D) - with batch normalization, RELU activation\n",
    "    # Global max pooling\n",
    "    # Some dense fully connected layers - with batch normalization, RELU activation\n",
    "    x = conv_bn(inputs, 32)\n",
    "    x = conv_bn(x, 64)\n",
    "    x = conv_bn(x, 512)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = dense_bn(x, 256)\n",
    "    x = dense_bn(x, 128)\n",
    "    # final layer with custom regularizer on the output\n",
    "    # TODO: this custom regularizer needs to be defined\n",
    "    x = layers.Dense(\n",
    "        num_features * num_features,\n",
    "        kernel_initializer=\"zeros\",\n",
    "        bias_initializer=bias,\n",
    "        activity_regularizer=CustomRegularizer(num_features))(x)\n",
    "    feat_t = layers.Reshape((num_features, num_features))(x)\n",
    "    # Apply affine transformation to input features\n",
    "    return layers.Dot(axes=(2, 1))([inputs, feat_t])\n",
    "\n",
    "\n",
    "class CustomRegularizer(keras.regularizers.Regularizer):\n",
    "    \"\"\"\n",
    "    This class implements a regularizer that makes the output to be orthogonal.\n",
    "    In other words, it adds a loss |I-AA^T|^2 on the output A. Equation 2 of the paper.\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, weight=0.001):\n",
    "        \"\"\"\n",
    "        Initializes the class\n",
    "        :param dim: dimensions of the input tensor\n",
    "        :type dim: int\n",
    "        :param weight: weight to apply on the regularizer\n",
    "        :type weight: float\n",
    "        \"\"\"\n",
    "        self.dim = dim\n",
    "        self.weight = weight\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # TODO: define the custom regularizer here\n",
    "        x = tf.reshape(x, (-1, self.dim, self.dim))\n",
    "        # compute the outer product and reshape it to batch size x num_features x num_features\n",
    "        xxt = tf.tensordot(x, x, axes=(2, 2))\n",
    "        xxt = tf.reshape(xxt, (-1, self.dim, self.dim))\n",
    "        # Compute (I-outerproduct)^2 element wise. use tf.square()\n",
    "        # Apply weight\n",
    "        # Compute reduce sum using tf.reduce_sum()\n",
    "        output = tf.reduce_sum(self.weight*tf.square(tf.eye(self.dim)-xxt))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = tf.random.uniform(shape=[1,1024,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1024, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tnet(sample, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1024, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6382069a7793f11ca2e4d453d6ea9dbfa636d21dc26e68dacc4c30284fcf592e"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('prithvi': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}